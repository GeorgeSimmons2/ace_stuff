{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea50698",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "using LinearAlgebra, Distributions, Random, Plots\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Define a toy ground-truth function\n",
    "# ----------------------------\n",
    "# (replace the simple f_true and small dataset with a much harder, nonstationary\n",
    "# function and many more training points)\n",
    "function f_true(x)\n",
    "    # multi-scale base + amplitude modulation\n",
    "    base = sin(3x) + 0.5*cos(9x)\n",
    "    modulation = 0.5*sin(2x) * (1 + 0.8*sin(25x))    # slowly varying amplitude with fast wiggles\n",
    "\n",
    "    # localized high-frequency burst (sharp, non-smooth feature)\n",
    "    burst = 0.9 * cos(60x) * exp(-40*(x - 1.0)^2)\n",
    "\n",
    "    # very sharp, narrow spikes (near-discontinuous behavior)\n",
    "    spikes = 0.8*exp(-200*(x - 0.5)^2) + 0.6*exp(-300*(x - 2.0)^2)\n",
    "\n",
    "    # a step/shift\n",
    "    step = x > π ? 0.7 : 0.0\n",
    "\n",
    "    return base + modulation + burst + spikes + step\n",
    "end\n",
    "\n",
    "Random.seed!(0)\n",
    "\n",
    "# Much larger training set (adjust Ntrain if memory/compute is an issue)\n",
    "Ntrain = 2000          # \"way way more data\"\n",
    "X = collect(range(0, 2π; length=Ntrain))\n",
    "y = f_true.(X) .+ 0.05 .* randn(Ntrain)\n",
    "\n",
    "# Denser test grid\n",
    "Xtest = collect(range(0, 2π; length=2000))\n",
    "ytrue = f_true.(Xtest)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Define an RBF kernel (too smooth on purpose)\n",
    "# ----------------------------\n",
    "function kernel(x1::AbstractVector, x2::AbstractVector; ℓ=1.0, σf=1.0)\n",
    "    n1, n2 = length(x1), length(x2)\n",
    "    K = zeros(Float64, n1, n2)\n",
    "    for i in 1:n1, j in 1:n2\n",
    "        K[i,j] = σf^2 * exp(-0.5 * ((x1[i]-x2[j])/ℓ)^2)\n",
    "    end\n",
    "    return K\n",
    "end\n",
    "\n",
    "ℓ = 1.0      # too large => oversmooths data\n",
    "σf = 1.0\n",
    "σn = 0.05\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Fit standard GP posterior mean\n",
    "# ----------------------------\n",
    "K = kernel(X, X; ℓ=ℓ, σf=σf) + σn^2 * I(length(X))\n",
    "L = cholesky(K)\n",
    "α = L \\ (L' \\ y)  # (K + σn^2 I)^(-1) y\n",
    "\n",
    "# Predictive mean on grid\n",
    "Kxx = kernel(X, X; ℓ=ℓ, σf=σf)                # kernel matrix without noise\n",
    "K = Kxx + σn^2 * I(length(X))                # covariance used for inference (with noise)\n",
    "L = cholesky(K)\n",
    "α = L \\ (L' \\ y)                             # (K + σn^2 I)^(-1) y\n",
    "\n",
    "# Predictive mean on grid\n",
    "Kx = kernel(Xtest, X; ℓ=ℓ, σf=σf)\n",
    "μ = Kx * α\n",
    "\n",
    "# mean at training points (avoid searching Xtest)\n",
    "μ_train = Kxx * α\n",
    "\n",
    "# ----------------------------\n",
    "# 4. POPS function-space corrections\n",
    "# ----------------------------\n",
    "Kdiag = diag(Kxx)                            # k(x_i,x_i) (no noise)\n",
    "μ_pops = zeros(length(X), length(X))\n",
    "\n",
    "for i in 1:length(X)\n",
    "    # Compute the residual at that training point (using μ_train)\n",
    "    δ = y[i] - μ_train[i]\n",
    "\n",
    "    # Minimal-norm kernel correction coefficient\n",
    "    α_i = δ / Kdiag[i]\n",
    "\n",
    "    # Apply correction across the test grid\n",
    "    μ_pops[:, i] = μ .+ α_i .* kernel(X, [X[i]]; ℓ=ℓ, σf=σf)[:,1]\n",
    "end\n",
    "\n",
    "μ_min = minimum(μ_pops, dims=2)\n",
    "μ_max = maximum(μ_pops, dims=2)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Plot results\n",
    "# ----------------------------\n",
    "plt = plot(Xtest, ytrue, lw=2, label=\"True f(x)\", color=:black)\n",
    "plot!(plt, Xtest, μ, lw=2, label=\"GP mean (misspecified)\", color=:blue)\n",
    "plot!(plt, Xtest, μ_min, lw=1, ls=:dash, color=:red, label=\"POPS envelope\")\n",
    "plot!(plt, Xtest, μ_max, lw=1, ls=:dash, color=:red, label=\"\")\n",
    "scatter!(plt, X, y; markersize=0.6, markerstrokewidth=0, marker=:dot, color=:black, alpha=0.6, label=\"Data\")\n",
    "xlabel!(\"x\"); ylabel!(\"y\")\n",
    "title!(\"GP misspecification and POPS function-space corrections\")\n",
    "display(plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56c501ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPS envelope test passed: all training points enclosed.\n"
     ]
    }
   ],
   "source": [
    "using Test, LinearAlgebra, Random\n",
    "\n",
    "# --- reproducible, small but nontrivial problem ---\n",
    "Random.seed!(42)\n",
    "\n",
    "function f_true(x)\n",
    "    base = sin(3x) + 0.5*cos(9x)\n",
    "    modulation = 0.5*sin(2x) * (1 + 0.8*sin(25x))\n",
    "    burst = 0.9 * cos(60x) * exp(-40*(x - 1.0)^2)\n",
    "    spikes = 0.8*exp(-200*(x - 0.5)^2) + 0.6*exp(-300*(x - 2.0)^2)\n",
    "    step = x > π ? 0.7 : 0.0\n",
    "    return base + modulation + burst + spikes + step\n",
    "end\n",
    "\n",
    "function kernel(x1::AbstractVector, x2::AbstractVector; ℓ=1.0, σf=1.0)\n",
    "    n1, n2 = length(x1), length(x2)\n",
    "    K = zeros(Float64, n1, n2)\n",
    "    for i in 1:n1, j in 1:n2\n",
    "        K[i,j] = σf^2 * exp(-0.5 * ((x1[i]-x2[j])/ℓ)^2)\n",
    "    end\n",
    "    return K\n",
    "end\n",
    "\n",
    "# small but representative dataset (fast to test)\n",
    "Ntrain = 120\n",
    "X = collect(range(0, 2π; length=Ntrain))\n",
    "y = f_true.(X) .+ 0.02 .* randn(Ntrain)\n",
    "\n",
    "ℓ = 1.0; σf = 1.0; σn = 0.05\n",
    "\n",
    "# GP posterior mean at training inputs (using noise in inference matrix)\n",
    "Kxx = kernel(X, X; ℓ=ℓ, σf=σf)           # kernel without noise\n",
    "K = Kxx + σn^2 * I(Ntrain)\n",
    "L = cholesky(K)\n",
    "α = L \\ (L' \\ y)\n",
    "μ_train = Kxx * α\n",
    "\n",
    "# POPS function-space corrections evaluated at training inputs\n",
    "Kdiag = diag(Kxx)\n",
    "μ_pops_train = zeros(Ntrain, Ntrain)\n",
    "for i in 1:Ntrain\n",
    "    δ = y[i] - μ_train[i]\n",
    "    α_i = δ / Kdiag[i]\n",
    "    μ_pops_train[:, i] .= μ_train .+ α_i .* kernel(X, [X[i]]; ℓ=ℓ, σf=σf)[:,1]\n",
    "end\n",
    "\n",
    "μ_min = vec(minimum(μ_pops_train, dims=2))\n",
    "μ_max = vec(maximum(μ_pops_train, dims=2))\n",
    "\n",
    "# numerical tolerance for floating rounding\n",
    "tol = 1e-12\n",
    "\n",
    "@test all(y .>= μ_min .- tol)  # all training targets are >= lower envelope\n",
    "@test all(y .<= μ_max .+ tol)  # all training targets are <= upper envelope\n",
    "\n",
    "println(\"POPS envelope test passed: all training points enclosed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748df322",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_true(x)\n",
    "    # multi-scale base + amplitude modulation\n",
    "    base = sin(3x) + 0.5*cos(9x)\n",
    "    modulation = 0.5*sin(2x) * (1 + 0.8*sin(25x))    # slowly varying amplitude with fast wiggles\n",
    "\n",
    "    # localized high-frequency burst (sharp, non-smooth feature)\n",
    "    burst = 0.9 * cos(60x) * exp(-40*(x - 1.0)^2)\n",
    "\n",
    "    # very sharp, narrow spikes (near-discontinuous behavior)\n",
    "    spikes = 0.8*exp(-200*(x - 0.5)^2) + 0.6*exp(-300*(x - 2.0)^2)\n",
    "\n",
    "    # a step/shift\n",
    "    step = x > π ? 0.7 : 0.0\n",
    "\n",
    "    return base + modulation + burst + spikes + step\n",
    "end\n",
    "\n",
    "Random.seed!(0)\n",
    "\n",
    "# Much larger training set (adjust Ntrain if memory/compute is an issue)\n",
    "Ntrain = 10\n",
    "X = collect(range(0, 2π; length=Ntrain))\n",
    "y = f_true.(X) .+ 0.05 .* randn(Ntrain)\n",
    "\n",
    "# Denser test grid\n",
    "Xtest = collect(range(0, 2π; length=10))\n",
    "ytrue = f_true.(Xtest)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Define an RBF kernel (too smooth on purpose)\n",
    "# ----------------------------\n",
    "function kernel(x1::AbstractVector, x2::AbstractVector; ℓ=1.0, σf=1.0)\n",
    "    n1, n2 = length(x1), length(x2)\n",
    "    K = zeros(Float64, n1, n2)\n",
    "    for i in 1:n1, j in 1:n2\n",
    "        K[i,j] = σf^2 * exp(-0.5 * ((x1[i]-x2[j])/ℓ)^2)\n",
    "    end\n",
    "    return K\n",
    "end\n",
    "\n",
    "ℓ = 1.0      # too large => oversmooths data\n",
    "σf = 1.0\n",
    "σn = 0.05\n",
    "X = collect(range(0, 2π; length=Ntrain))\n",
    "y = f_true.(X) #.+ 0.0005 .* randn(Ntrain)\n",
    "σn= 1e-1\n",
    "K = kernel(X, X; ℓ=ℓ, σf=1.0) + σn^2 * I(length(X))\n",
    "Kxx = kernel(Xtest, X; ℓ=ℓ, σf=σf)\n",
    "L = cholesky(K)\n",
    "α = L \\ (L' \\ y);  # (K + σn^2 I)^(-1) y\n",
    "y_predict = Kxx * α\n",
    "error = y .- y_predict\n",
    "A = K \\ Kxx\n",
    "leverage = Kxx' * (A)\n",
    "pw = (error ./ leverage) * A\n",
    "y_pops = []\n",
    "for i = 1:size(pw,1)\n",
    "  pw[i,:] .+= α\n",
    "  push!(y_pops, Kxx * pw[i,:])\n",
    "end\n",
    "μ_min = minimum(y_pops, dims=2)\n",
    "μ_max = maximum(y_pops, dims=2)\n",
    "plt = plot(X, y, lw=2, label=\"True f(x)\", color=:black)\n",
    "plot!(plt, X, y_predict, lw=2, label=\"GP mean (misspecified)\", color=:blue)\n",
    "plot!(plt, X, y_predict, lw=2, label=\"GP mean (misspecified)\", color=:blue)\n",
    "plot!(plt, X, μ_min, lw=1, ls=:dash, color=:red, label=\"POPS envelope\")\n",
    "plot!(plt, X, μ_max, lw=1, ls=:dash, color=:red, label=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
